{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PanelSterowaniaGC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X-vmgtPj5lQj"
      ],
      "mount_file_id": "1B-_x0y_TIpOQwxUkzTUnAtKrtPyUHnOW",
      "authorship_tag": "ABX9TyNPCE69NwzTwhpDtBVXhYXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgontarz20/mgontarz20/blob/main/PanelSterowaniaGC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPD8zIwh3rl9"
      },
      "source": [
        "# Library Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNHDQWfK3xvG"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/BadaniaMchtr')\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "from keras.losses import MeanSquaredError, SparseCategoricalCrossentropy\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard,CSVLogger,LambdaCallback\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from datetime import datetime\n",
        "\n",
        "import json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi6UNaVE3qjk"
      },
      "source": [
        "#User Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_ZJYDAn32cm"
      },
      "source": [
        "import genConfig\n",
        "import plotter\n",
        "import UNetResNet_5lvl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQU1P43a38mS"
      },
      "source": [
        "# Definition of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f0z9tLM4CdM"
      },
      "source": [
        "test_size = 0.25\n",
        "random_state = 10\n",
        "n_filters = 4\n",
        "stop_patience = 21\n",
        "batch_size = 16\n",
        "epoch_limit = 200\n",
        "norm = False\n",
        "coeff = 1.0\n",
        "if norm:\n",
        "    coeff = 255.0\n",
        "activation_function = 'relu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QyLiROn04wi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-hU_2vJ0qFB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOUKqSY44I4D"
      },
      "source": [
        "#Name definition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJiQJekx4LCN"
      },
      "source": [
        "date = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
        "root = '/content/drive/MyDrive/BadaniaMchtr/'\n",
        "pathtoDataSet = f\"{root}Datasets/\"\n",
        "dataset = \"dataset_9_Combined_to_pred_256x256_10-11-2021_11-24-53\"\n",
        "type1 = \"resc_wrpd\"\n",
        "type2 = \"resc\"\n",
        "comment = \"SSIMloss\"\n",
        "name = f\"UNetResNet5lvl_{type1}_{date}_{comment}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FOZ67GT4ZeA"
      },
      "source": [
        "# Path Definition\n",
        "# Folder Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBL4_0_l4fDV"
      },
      "source": [
        "os.makedirs(f'{root}Results/{name}', exist_ok=True)\n",
        "os.makedirs(f'{root}Results/{name}/model', exist_ok=True)\n",
        "os.makedirs(f'{root}Results/{name}/cfg', exist_ok=True)\n",
        "cfg_dir = f'{root}Results/{name}/cfg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF3MZJn44lEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223b9115-f27b-40a4-f936-92ed7a754871"
      },
      "source": [
        "path_to_inputs = os.path.join(pathtoDataSet,dataset,type1).replace(\"\\\\\", \"/\")\n",
        "path_to_outputs = os.path.join(pathtoDataSet,dataset,type2).replace(\"\\\\\", \"/\")\n",
        "print(f\"Input path: {path_to_inputs}\")\n",
        "print(f\"Output path: {path_to_outputs}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input path: /content/drive/MyDrive/BadaniaMchtr/Datasets/dataset_9_Combined_to_pred_256x256_10-11-2021_11-24-53/resc_wrpd\n",
            "Output path: /content/drive/MyDrive/BadaniaMchtr/Datasets/dataset_9_Combined_to_pred_256x256_10-11-2021_11-24-53/resc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMeBrbF_5FEK"
      },
      "source": [
        "# Custom Functions (Callbacks, Loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m3H54wx4qSu"
      },
      "source": [
        "json_log = open(f'{root}Results/{name}/{name}_loss_log.json', mode='wt', buffering=1)\n",
        "json_logging_callback = LambdaCallback(\n",
        "    on_epoch_end=lambda epoch, logs: json_log.write(\n",
        "        json.dumps({'epoch': epoch, 'loss': logs['loss']}) + '\\n'),\n",
        "    on_train_end=lambda logs: json_log.close())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0k1FAKY5Q1G"
      },
      "source": [
        "def SSIMLoss(y_true, y_pred):\n",
        "  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 255.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIHo3Mbi5Opr"
      },
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(patience=stop_patience, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.0000001, verbose=1),\n",
        "    ModelCheckpoint(f'{root}Results/{name}/model/{name}.h5', verbose=1, save_best_only=True),\n",
        "    #Tensordash(ModelName=f\"{name}\", email='mgontarz15@gmail.com', password='dupadupa'),\n",
        "    TensorBoard(log_dir=f\"{root}Results/{name}/model/logs\", write_graph=True, write_images= True, update_freq=5),\n",
        "    CSVLogger(f\"{root}Results/{name}/model/{name}.csv\"),\n",
        "    json_logging_callback,\n",
        "            ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD8px2aI42vM"
      },
      "source": [
        "#Importing Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMFilVKI4457"
      },
      "source": [
        "# inputs = os.listdir(path_to_inputs)\n",
        "# outputs = os.listdir(path_to_outputs)\n",
        "# print(len(inputs))\n",
        "# print(len(outputs))\n",
        "# inputs.sort()\n",
        "# outputs.sort()\n",
        "\n",
        "# X = np.zeros((len(inputs), 256, 256, 1))\n",
        "# y = np.zeros((len(outputs), 256, 256, 1))\n",
        "# print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlqp44Pfrn5q"
      },
      "source": [
        "#!unrar x \"/content/drive/MyDrive/BadaniaMchtr/Datasets/dataset_9_Combined_to_pred_256x256_10-11-2021_11-24-53.rar\" \"/content/drive/MyDrive/BadaniaMchtr/Datasets/dataset_9_Combined_to_pred_256x256_10-11-2021_11-24-53/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUBnSaBRZZTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47811db1-67d4-412e-b558-17302e552e8e"
      },
      "source": [
        "X = np.load(\"/content/drive/MyDrive/BadaniaMchtr/Datasets/dataset_9_Combined_to_pred_256x256_10-11-2021_11-24-53/X.npy\")\n",
        "y = np.load(\"/content/drive/MyDrive/BadaniaMchtr/Datasets/dataset_9_Combined_to_pred_256x256_10-11-2021_11-24-53/y.npy\")\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5001, 256, 256, 1) (5001, 256, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRGujCW4rXwX"
      },
      "source": [
        "# for i in tqdm(range(len(inputs)), desc=\"IMPORTING IMAGES: \"):\n",
        "\n",
        "#     wrapped = img_to_array(load_img(os.path.join(path_to_inputs, inputs[i]).replace('\\\\','/'), color_mode=\"grayscale\"))\n",
        "#     wrapped = resize(wrapped, (256,256,1), mode = 'constant', preserve_range = True)\n",
        "#     # Load unwrapped images (outputs)\n",
        "#     unwrapped = img_to_array(load_img(os.path.join(path_to_outputs, outputs[i]).replace('\\\\','/'), color_mode=\"grayscale\"))\n",
        "#     unwrapped = resize(unwrapped, (256,256,1), mode = 'constant', preserve_range = True)\n",
        "\n",
        "#     X[i] = wrapped.astype('float32')/coeff\n",
        "#     y[i] = unwrapped.astype('float32')/coeff\n",
        "\n",
        "# print(len(X))\n",
        "# print(len(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axq9IlIA497E"
      },
      "source": [
        "genConfig.write_cfg(cfg_dir, name, 'w', type_input = type1, type_output= type2, dataset = dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxPWeH5X5dIp"
      },
      "source": [
        "# Train Test Splitting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOvcK16V5fEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58adf56a-8436-4a8b-c432-75952751f303"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n",
        "del X\n",
        "del y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3750, 256, 256, 1) (1251, 256, 256, 1) (3750, 256, 256, 1) (1251, 256, 256, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3uQuk5k5i2M"
      },
      "source": [
        "genConfig.write_cfg(cfg_dir, name, \"a\", test_size = test_size, random_state = random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-vmgtPj5lQj"
      },
      "source": [
        "#Model Loading and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfjkcFwi5oDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e66a7708-f4f0-4018-d78e-76875f738f24"
      },
      "source": [
        "input_img = Input((256, 256, 1), name='img')\n",
        "model = UNetResNet_5lvl.get_unet(input_img, n_filters=n_filters, activation=activation_function)\n",
        "model.compile(optimizer=Adam(learning_rate=0.01), loss=SSIMLoss,  metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "img (InputLayer)                [(None, 256, 256, 1) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 4)  40          img[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 4)  16          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 256, 4)  0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 4)  148         activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 4)  16          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256, 256, 4)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 4)  148         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 4)  16          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 256, 4)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256, 256, 4)  0           activation[0][0]                 \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 256, 256, 4)  148         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 256, 256, 4)  16          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 256, 256, 4)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 4)  0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 8)  296         max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 8)  32          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 8)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 128, 128, 8)  584         activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 128, 128, 8)  32          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 128, 128, 8)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 128, 128, 8)  584         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 128, 128, 8)  32          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 128, 128, 8)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 128, 128, 8)  0           activation_4[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 128, 128, 8)  584         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 128, 128, 8)  32          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 128, 128, 8)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 8)    0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 16)   1168        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 16)   64          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 64, 64, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 64, 64, 16)   2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 64, 64, 16)   64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 64, 64, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 64, 16)   2320        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 64, 16)   64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 64, 16)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 64, 16)   0           activation_8[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 16)   2320        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 64, 16)   64          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 64, 64, 16)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 16)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 32)   4640        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 32)   9248        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 32)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 32)   9248        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 32)   128         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 32)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 32)   0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 32)   9248        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 32)   128         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 32)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 32)   0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 64)   18496       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 64)   36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 64)   0           activation_16[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   36928       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 128)    73856       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 128)    512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 128)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 128)    147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 128)    512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 128)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 128)    147584      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 128)    512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 128)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 128)    0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 128)    147584      add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 128)    512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 128)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 16, 16, 64)   73792       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16, 16, 128)  0           conv2d_transpose[0][0]           \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 32)   36896       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 32)   128         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 32)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 32)   9248        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 32)   128         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 32)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 32)   9248        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 32)   128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 32)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 32)   0           activation_24[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 32)   9248        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 32)   9248        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 64)   0           conv2d_transpose_1[0][0]         \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 32)   18464       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 32, 32, 32)   128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 32, 32, 32)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 32)   9248        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 32, 32, 32)   128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 32, 32, 32)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 32)   9248        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 32, 32, 32)   128         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 32)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 32, 32, 32)   0           activation_28[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 32)   9248        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 32, 32, 32)   128         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 16)   4624        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 32)   0           conv2d_transpose_2[0][0]         \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 64, 64, 16)   4624        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 64, 64, 16)   64          conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 64, 64, 16)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 64, 64, 16)   2320        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 64, 64, 16)   64          conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 64, 64, 16)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 64, 64, 16)   2320        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 64, 64, 16)   64          conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 64, 64, 16)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 64, 64, 16)   0           activation_32[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 64, 64, 16)   2320        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 64, 64, 16)   64          conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 64, 64, 16)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 8)  1160        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 16) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 128, 128, 8)  1160        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 128, 128, 8)  32          conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 128, 128, 8)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 128, 128, 8)  584         activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 128, 128, 8)  32          conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 128, 128, 8)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 128, 128, 8)  584         activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 128, 128, 8)  32          conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 128, 128, 8)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 128, 128, 8)  0           activation_36[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 128, 128, 8)  584         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 128, 128, 8)  32          conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 128, 128, 8)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 4)  292         activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 256, 256, 8)  0           conv2d_transpose_4[0][0]         \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 256, 256, 4)  292         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 256, 256, 4)  16          conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 256, 256, 4)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 256, 256, 4)  148         activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 256, 256, 4)  16          conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 256, 256, 4)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 256, 256, 4)  148         activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 256, 256, 4)  16          conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 256, 256, 4)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 256, 256, 4)  0           activation_40[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 256, 256, 4)  148         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 256, 256, 4)  16          conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 256, 256, 4)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 256, 256, 1)  5           activation_43[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 909,637\n",
            "Trainable params: 906,885\n",
            "Non-trainable params: 2,752\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO4fl63B5wwv"
      },
      "source": [
        "genConfig.write_cfg(cfg_dir,name, 'a', optimizer = \"Adam\", loss = comment, metrics = \"accuracy\", state = \"new\", n_filters = n_filters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtJajT8U51Cb"
      },
      "source": [
        "#Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY7mXctB53bG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae77495-e322-4607-816f-555d82781b60"
      },
      "source": [
        "start = datetime.now()\n",
        "results = model.fit(X_train, y_train, batch_size=batch_size, epochs=epoch_limit, callbacks=callbacks,\n",
        "                     validation_data=(X_valid, y_valid))\n",
        "\n",
        "stop = datetime.now()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "235/235 [==============================] - 116s 333ms/step - loss: 0.2366 - accuracy: 0.0853 - val_loss: 0.1544 - val_accuracy: 0.0419\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.15444, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 2/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0444 - accuracy: 0.0924 - val_loss: 0.0440 - val_accuracy: 0.0955\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.15444 to 0.04401, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 3/200\n",
            "235/235 [==============================] - 69s 295ms/step - loss: 0.0210 - accuracy: 0.0931 - val_loss: 0.0350 - val_accuracy: 0.0743\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.04401 to 0.03500, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 4/200\n",
            "235/235 [==============================] - 73s 312ms/step - loss: 0.0184 - accuracy: 0.0948 - val_loss: 0.0321 - val_accuracy: 0.0952\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.03500 to 0.03210, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 5/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0115 - accuracy: 0.0953 - val_loss: 0.0130 - val_accuracy: 0.0443\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.03210 to 0.01300, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 6/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0109 - accuracy: 0.0948 - val_loss: 0.2446 - val_accuracy: 0.0525\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.01300\n",
            "Epoch 7/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0124 - accuracy: 0.0943 - val_loss: 0.0160 - val_accuracy: 0.0919\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.01300\n",
            "Epoch 8/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0093 - accuracy: 0.0944 - val_loss: 0.0205 - val_accuracy: 0.0437\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.01300\n",
            "Epoch 9/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0094 - accuracy: 0.0958 - val_loss: 0.0131 - val_accuracy: 0.0938\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.01300\n",
            "Epoch 10/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0128 - accuracy: 0.0885 - val_loss: 0.0120 - val_accuracy: 0.0948\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.01300 to 0.01203, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 11/200\n",
            "235/235 [==============================] - 69s 296ms/step - loss: 0.0110 - accuracy: 0.0925 - val_loss: 0.3065 - val_accuracy: 0.0471\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.01203\n",
            "Epoch 12/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0115 - accuracy: 0.0932 - val_loss: 0.0052 - val_accuracy: 0.0922\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.01203 to 0.00522, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 13/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0081 - accuracy: 0.0949 - val_loss: 0.0113 - val_accuracy: 0.0945\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.00522\n",
            "Epoch 14/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0070 - accuracy: 0.0951 - val_loss: 0.0041 - val_accuracy: 0.0933\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.00522 to 0.00410, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 15/200\n",
            "235/235 [==============================] - 69s 296ms/step - loss: 0.0058 - accuracy: 0.0956 - val_loss: 0.0048 - val_accuracy: 0.0935\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.00410\n",
            "Epoch 16/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0060 - accuracy: 0.0952 - val_loss: 0.0031 - val_accuracy: 0.0942\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.00410 to 0.00307, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 17/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0079 - accuracy: 0.0954 - val_loss: 0.0295 - val_accuracy: 0.0948\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.00307\n",
            "Epoch 18/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0048 - accuracy: 0.0956 - val_loss: 0.0061 - val_accuracy: 0.0949\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.00307\n",
            "Epoch 19/200\n",
            "235/235 [==============================] - 73s 312ms/step - loss: 0.0076 - accuracy: 0.0951 - val_loss: 0.0245 - val_accuracy: 0.0933\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.00307\n",
            "Epoch 20/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0068 - accuracy: 0.0950 - val_loss: 0.0034 - val_accuracy: 0.0933\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.00307\n",
            "Epoch 21/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0056 - accuracy: 0.0954 - val_loss: 0.0165 - val_accuracy: 0.0954\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.00307\n",
            "Epoch 22/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0046 - accuracy: 0.0961 - val_loss: 0.0019 - val_accuracy: 0.0948\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.00307 to 0.00188, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 23/200\n",
            "235/235 [==============================] - 73s 312ms/step - loss: 0.0041 - accuracy: 0.0963 - val_loss: 0.0021 - val_accuracy: 0.0948\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.00188\n",
            "Epoch 24/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0041 - accuracy: 0.0961 - val_loss: 0.0016 - val_accuracy: 0.0951\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.00188 to 0.00164, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 25/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0040 - accuracy: 0.0961 - val_loss: 0.0020 - val_accuracy: 0.0951\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.00164\n",
            "Epoch 26/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0038 - accuracy: 0.0958 - val_loss: 0.0022 - val_accuracy: 0.0964\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.00164\n",
            "Epoch 27/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0036 - accuracy: 0.0963 - val_loss: 0.0016 - val_accuracy: 0.0954\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.00164 to 0.00155, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 28/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0035 - accuracy: 0.0960 - val_loss: 0.0016 - val_accuracy: 0.0958\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.00155\n",
            "Epoch 29/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0035 - accuracy: 0.0956 - val_loss: 0.0017 - val_accuracy: 0.0959\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.00155\n",
            "Epoch 30/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0035 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0957\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.00155 to 0.00138, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 31/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0032 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0958\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.00138\n",
            "Epoch 32/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0033 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.00138\n",
            "Epoch 33/200\n",
            "235/235 [==============================] - 69s 295ms/step - loss: 0.0035 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0958\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.00138\n",
            "Epoch 34/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0032 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0958\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.00138\n",
            "Epoch 35/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0035 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.00138 to 0.00138, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 36/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0034 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.00138\n",
            "Epoch 37/200\n",
            "235/235 [==============================] - 73s 312ms/step - loss: 0.0033 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.00138 to 0.00137, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 38/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0031 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.00137 to 0.00137, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 39/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0030 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.00137\n",
            "Epoch 40/200\n",
            "235/235 [==============================] - 73s 312ms/step - loss: 0.0033 - accuracy: 0.0956 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.00137\n",
            "Epoch 41/200\n",
            "235/235 [==============================] - 73s 312ms/step - loss: 0.0031 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.00137 to 0.00136, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 42/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0033 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.00136 to 0.00136, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 43/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0032 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.00136 to 0.00136, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 44/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0036 - accuracy: 0.0957 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.00136 to 0.00136, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 45/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0032 - accuracy: 0.0960 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.00136\n",
            "Epoch 46/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0034 - accuracy: 0.0960 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.00136\n",
            "Epoch 47/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0031 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.00136\n",
            "Epoch 48/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0034 - accuracy: 0.0959 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.00136\n",
            "Epoch 49/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0034 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.00136\n",
            "Epoch 50/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0033 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.00136\n",
            "Epoch 51/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0036 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.00136\n",
            "Epoch 52/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0031 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.00136\n",
            "Epoch 53/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0032 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.00136 to 0.00135, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 54/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0037 - accuracy: 0.0954 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.00135\n",
            "Epoch 55/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0034 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.00135\n",
            "Epoch 56/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0036 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.00135\n",
            "Epoch 57/200\n",
            "235/235 [==============================] - 73s 313ms/step - loss: 0.0034 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.00135\n",
            "Epoch 58/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0030 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.00135\n",
            "Epoch 59/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0033 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.00135\n",
            "Epoch 60/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0031 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.00135\n",
            "Epoch 61/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0033 - accuracy: 0.0959 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.00135\n",
            "Epoch 62/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0031 - accuracy: 0.0959 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.00135\n",
            "Epoch 63/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0032 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.00135\n",
            "Epoch 64/200\n",
            "235/235 [==============================] - 69s 296ms/step - loss: 0.0033 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.00135\n",
            "Epoch 65/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0034 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.00135\n",
            "Epoch 66/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0032 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.00135\n",
            "Epoch 67/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0034 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.00135\n",
            "Epoch 68/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0029 - accuracy: 0.0964 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.00135\n",
            "Epoch 69/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0033 - accuracy: 0.0964 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.00135 to 0.00135, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 70/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0032 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.00135\n",
            "Epoch 71/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0034 - accuracy: 0.0959 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.00135\n",
            "Epoch 72/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0032 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.00135\n",
            "Epoch 73/200\n",
            "235/235 [==============================] - 74s 315ms/step - loss: 0.0035 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.00135\n",
            "Epoch 74/200\n",
            "235/235 [==============================] - 70s 298ms/step - loss: 0.0032 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.00135\n",
            "Epoch 75/200\n",
            "235/235 [==============================] - 70s 298ms/step - loss: 0.0031 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.00135\n",
            "Epoch 76/200\n",
            "235/235 [==============================] - 70s 298ms/step - loss: 0.0035 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.00135\n",
            "Epoch 77/200\n",
            "235/235 [==============================] - 70s 298ms/step - loss: 0.0032 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.00135\n",
            "Epoch 78/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0033 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.00135\n",
            "Epoch 79/200\n",
            "235/235 [==============================] - 69s 295ms/step - loss: 0.0033 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.00135\n",
            "Epoch 80/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0031 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.00135\n",
            "Epoch 81/200\n",
            "235/235 [==============================] - 69s 295ms/step - loss: 0.0035 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.00135\n",
            "Epoch 82/200\n",
            "235/235 [==============================] - 73s 312ms/step - loss: 0.0031 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.00135\n",
            "Epoch 83/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0033 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.00135\n",
            "Epoch 84/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0029 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.00135\n",
            "Epoch 85/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0030 - accuracy: 0.0962 - val_loss: 0.0013 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.00135 to 0.00135, saving model to /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5\n",
            "Epoch 86/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0033 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.00135\n",
            "Epoch 87/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0032 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.00135\n",
            "Epoch 88/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0032 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.00135\n",
            "Epoch 89/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0031 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.00135\n",
            "Epoch 90/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0035 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.00135\n",
            "Epoch 91/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0036 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.00135\n",
            "Epoch 92/200\n",
            "235/235 [==============================] - 74s 313ms/step - loss: 0.0032 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.00135\n",
            "Epoch 93/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0029 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.00135\n",
            "Epoch 94/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0033 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.00135\n",
            "Epoch 95/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0031 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.00135\n",
            "Epoch 96/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0031 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.00135\n",
            "Epoch 97/200\n",
            "235/235 [==============================] - 70s 296ms/step - loss: 0.0031 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.00135\n",
            "Epoch 98/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0031 - accuracy: 0.0963 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.00135\n",
            "Epoch 99/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0032 - accuracy: 0.0961 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.00135\n",
            "Epoch 100/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0039 - accuracy: 0.0951 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.00135\n",
            "Epoch 101/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0031 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.00135\n",
            "Epoch 102/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0033 - accuracy: 0.0962 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.00135\n",
            "Epoch 103/200\n",
            "235/235 [==============================] - 74s 314ms/step - loss: 0.0030 - accuracy: 0.0959 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.00135\n",
            "Epoch 104/200\n",
            "235/235 [==============================] - 70s 298ms/step - loss: 0.0034 - accuracy: 0.0959 - val_loss: 0.0014 - val_accuracy: 0.0960\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.00135\n",
            "Epoch 105/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0035 - accuracy: 0.0954 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.00135\n",
            "Epoch 106/200\n",
            "235/235 [==============================] - 70s 297ms/step - loss: 0.0034 - accuracy: 0.0959 - val_loss: 0.0014 - val_accuracy: 0.0961\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.00135\n",
            "Epoch 00106: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaTS-Phl57JH"
      },
      "source": [
        "time = stop - start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCiJUFED576J"
      },
      "source": [
        "genConfig.write_cfg(cfg_dir,name, \"a\", batch_size = batch_size, epoch_limit = epoch_limit, time = time, activation_function = activation_function)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xBhPseU5_pP"
      },
      "source": [
        "#Plotting Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54rgm4sQ6B_0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKlMp4fP6DvJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "812b8052-9753-49c7-8e73-1b967339501d"
      },
      "source": [
        "plotter.plot_model_data(model, name, results, root)\n",
        "genConfig.write_cfg(cfg_dir,name, \"a\",  best_loss = np.min(results.history[\"val_loss\"]), for_epoch_loss = np.argmin(results.history[\"val_loss\"]), best_acc = np.max(results.history[\"val_accuracy\"]), for_epoch_acc = np.argmax(results.history[\"val_accuracy\"]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.497737 to fit\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aTb-t6i6GUQ"
      },
      "source": [
        "#Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmKoDryz6Iio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ad9981-0b11-4ab1-f70d-5812f71e5e34"
      },
      "source": [
        "score, acc = model.evaluate(X_train, y_train,\n",
        "                            batch_size=batch_size)\n",
        "print('Train score:', score)\n",
        "print('Train accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235/235 [==============================] - 20s 86ms/step - loss: 0.0013 - accuracy: 0.0974\n",
            "Train score: 0.0012977768201380968\n",
            "Train accuracy: 0.0974162146449089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJBWrmf46LYE"
      },
      "source": [
        "genConfig.write_cfg(cfg_dir,name, \"a\", train_score = score, train_acc =acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUTlvV476MWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8286edf-ab9c-444b-e861-7760707fbd0c"
      },
      "source": [
        "score, acc = model.evaluate(X_valid, y_valid,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 7s 86ms/step - loss: 0.0014 - accuracy: 0.0961\n",
            "Test score: 0.0013648903695866466\n",
            "Test accuracy: 0.09610448777675629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7gQ9g696PpS"
      },
      "source": [
        "genConfig.write_cfg(cfg_dir,name, \"a\", test_score = score, test_acc =acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axl_aAmXFmIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f44d97-4d42-43ba-ce33-071e95f66889"
      },
      "source": [
        "!apt-get install rar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  rar\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 295 kB of archives.\n",
            "After this operation, 799 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 rar amd64 2:5.5.0-1 [295 kB]\n",
            "Fetched 295 kB in 1s (470 kB/s)\n",
            "Selecting previously unselected package rar.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../rar_2%3a5.5.0-1_amd64.deb ...\n",
            "Unpacking rar (2:5.5.0-1) ...\n",
            "Setting up rar (2:5.5.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkBX7_-KplhS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "734534e9-0648-4c0b-be20-e290c5af1db0"
      },
      "source": [
        "name = \"UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss\"\n",
        "!rar a '/content/drive/MyDrive/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss_Results' '/content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss'\n",
        "from google.colab import files\n",
        "files.download(\"/content/drive/MyDrive/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss_Results.rar\")\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RAR 5.50   Copyright (c) 1993-2017 Alexander Roshal   11 Aug 2017\n",
            "Trial version             Type 'rar -?' for help\n",
            "\n",
            "Evaluation copy. Please register.\n",
            "\n",
            "Creating archive /content/drive/MyDrive/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss_Results.rar\n",
            "\n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/events.out.tfevents.1634249645.1ae09c138269.profile-empty     \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile/2021_10_14_22_14_05/1ae09c138269.trace.json.gz     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile/2021_10_14_22_14_05/1ae09c138269.memory_profile.json.gz     \b\b\b\b  1%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile/2021_10_14_22_14_05/1ae09c138269.xplane.pb     \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile/2021_10_14_22_14_05/1ae09c138269.overview_page.pb     \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile/2021_10_14_22_14_05/1ae09c138269.input_pipeline.pb     \b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile/2021_10_14_22_14_05/1ae09c138269.tensorflow_stats.pb     \b\b\b\b  8%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile/2021_10_14_22_14_05/1ae09c138269.kernel_stats.pb     \b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/events.out.tfevents.1634249606.1ae09c138269.1566.0.v2     \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/validation/events.out.tfevents.1634249710.1ae09c138269.1566.1.v2     \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.csv     \b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.h5     \b\b\b\b 42%\b\b\b\b 65%\b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/cfg/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.txt     \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss_loss_log.json     \b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMlossmodel_'LR'.jpg     \b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMlossmodel_'TB'.jpg     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/loss_UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.jpg     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/acc_UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss.jpg     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile/2021_10_14_22_14_05     \b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins/profile     \b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train/plugins     \b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/train     \b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs/validation     \b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model/logs     \b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/model     \b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss/cfg     \b\b\b\b\b  OK \n",
            "Adding    /content/drive/MyDrive/BadaniaMchtr/Results/UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss     \b\b\b\b\b  OK \n",
            "Done\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c529574e-30e9-4f19-9358-66b5e0c934fb\", \"UNetResNet5lvl_resc_wrpd_10-14-2021_22-11-02_SSIMloss_Results.rar\", 12260366)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX3CACHIvv1L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twx05D5Qvy8E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}